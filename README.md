# Cross-Script Knowledge Distillation for Bangla NLP:Transliteration-Driven Compression of Large Transformer Models


Repo goal. This repository contains code, configs, and results for a comprehensive study of cross-lingual transfer (EN→HI→UR→BN) across three core Bangla NLP tasks — POS Tagging, Dependency Parsing, and Sentence Classification — plus script-aware Knowledge Distillation (KD) from XLM-R → RoBERTa using transliteration and shared-tokenizer strategies.Placeholder main branch

This branch is intentionally minimal; code lives on feature branches.
