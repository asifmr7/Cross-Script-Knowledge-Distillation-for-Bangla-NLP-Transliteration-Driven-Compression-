{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13548139,"sourceType":"datasetVersion","datasetId":8604449},{"sourceId":13548161,"sourceType":"datasetVersion","datasetId":8604468}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip -q install -U \"transformers>=4.41\" \"datasets>=2.19\" stanza==1.5.0 conllu==6.0.0 seqeval==1.2.2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-29T22:22:11.621498Z","iopub.execute_input":"2025-10-29T22:22:11.622168Z","iopub.status.idle":"2025-10-29T22:23:51.864832Z","shell.execute_reply.started":"2025-10-29T22:22:11.622133Z","shell.execute_reply":"2025-10-29T22:23:51.863992Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m802.5/802.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m506.8/506.8 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import sys\nsys.path.insert(0, \"/kaggle/working/libs\")\n\n# purge any already-imported copies (including submodules)\nfor name in list(sys.modules.keys()):\n    if name == \"transformers\" or name.startswith(\"transformers.\"):\n        del sys.modules[name]\n    if name == \"tokenizers\" or name.startswith(\"tokenizers.\"):\n        del sys.modules[name]\n    if name == \"huggingface_hub\" or name.startswith(\"huggingface_hub.\"):\n        del sys.modules[name]\n\nimport transformers, tokenizers, huggingface_hub\nprint(\"transformers:\", transformers.__version__, transformers.__file__)\nprint(\"tokenizers:\", tokenizers.__version__, tokenizers.__file__)\nprint(\"huggingface_hub:\", huggingface_hub.__version__, huggingface_hub.__file__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T22:24:55.639508Z","iopub.execute_input":"2025-10-29T22:24:55.640284Z","iopub.status.idle":"2025-10-29T22:24:59.904222Z","shell.execute_reply.started":"2025-10-29T22:24:55.640242Z","shell.execute_reply":"2025-10-29T22:24:59.903298Z"}},"outputs":[{"name":"stdout","text":"transformers: 4.57.1 /usr/local/lib/python3.11/dist-packages/transformers/__init__.py\ntokenizers: 0.22.1 /usr/local/lib/python3.11/dist-packages/tokenizers/__init__.py\nhuggingface_hub: 0.36.0 /usr/local/lib/python3.11/dist-packages/huggingface_hub/__init__.py\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"%%writefile setup.py\nimport os\nimport shutil\n\ndef safe_makedirs(path: str):\n    \"\"\"Safely create directory path (handle existing files).\"\"\"\n    path = os.path.normpath(path)\n    if not path or path == '.':\n        return\n    if os.path.exists(path):\n        if os.path.isdir(path):\n            return\n        else:\n            os.remove(path)\n    parent = os.path.dirname(path)\n    if parent and parent != path:\n        if os.path.exists(parent):\n            if not os.path.isdir(parent):\n                os.remove(parent)\n                safe_makedirs(parent)\n        else:\n            safe_makedirs(parent)\n    os.makedirs(path, exist_ok=True)\n\ndef main():\n    print(\"Setting up (offline mode)â€¦\")\n\n    # âœ… Create unified writable data directory\n    data_dir = \"/kaggle/working/data/ud\"\n    safe_makedirs(data_dir)\n\n    # âœ… Define local dataset sources (read-only)\n    en_source = \"/kaggle/input/english-data\"\n    bn_source = \"/kaggle/input/bangla-dataaaaaaaa\"\n\n    # âœ… Define expected files and their locations\n    files = {\n        \"en_ewt-ud-train.conllu\": os.path.join(en_source, \"en_ewt-ud-train.conllu\"),\n        \"en_ewt-ud-dev.conllu\": os.path.join(en_source, \"en_ewt-ud-dev.conllu\"),\n        \"bn_bru-ud-test.conllu\": os.path.join(bn_source, \"bn_bru-ud-test.conllu\"),\n    }\n\n    # âœ… Copy each file into /kaggle/working/data/ud/\n    for fname, src in files.items():\n        dst = os.path.join(data_dir, fname)\n        if os.path.exists(dst):\n            print(f\"âœ” {fname} already in place\")\n        elif os.path.exists(src):\n            shutil.copy(src, dst)\n            print(f\"ğŸ“‚ Copied {fname} â†’ {dst}\")\n        else:\n            print(f\"âš  Missing source file: {src}\")\n\n    print(\"âœ… Offline setup complete!\")\n    print(f\"   All writable data is now in: {data_dir}\")\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T22:25:06.920430Z","iopub.execute_input":"2025-10-29T22:25:06.921146Z","iopub.status.idle":"2025-10-29T22:25:06.927475Z","shell.execute_reply.started":"2025-10-29T22:25:06.921121Z","shell.execute_reply":"2025-10-29T22:25:06.926434Z"}},"outputs":[{"name":"stdout","text":"Writing setup.py\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!python setup.py\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T22:25:11.207976Z","iopub.execute_input":"2025-10-29T22:25:11.208274Z","iopub.status.idle":"2025-10-29T22:25:11.738106Z","shell.execute_reply.started":"2025-10-29T22:25:11.208253Z","shell.execute_reply":"2025-10-29T22:25:11.737266Z"}},"outputs":[{"name":"stdout","text":"Setting up (offline mode)â€¦\nğŸ“‚ Copied en_ewt-ud-train.conllu â†’ /kaggle/working/data/ud/en_ewt-ud-train.conllu\nğŸ“‚ Copied en_ewt-ud-dev.conllu â†’ /kaggle/working/data/ud/en_ewt-ud-dev.conllu\nğŸ“‚ Copied bn_bru-ud-test.conllu â†’ /kaggle/working/data/ud/bn_bru-ud-test.conllu\nâœ… Offline setup complete!\n   All writable data is now in: /kaggle/working/data/ud\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"%%writefile postaging.py\nimport os\n# Quiet noisy libs BEFORE importing HF/Torch\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\nos.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport random\nimport warnings\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom conllu import parse_incr\nfrom datasets import Dataset\nfrom transformers import (\n    AutoTokenizer, AutoModelForTokenClassification,\n    Trainer, TrainingArguments, DataCollatorForTokenClassification, set_seed\n)\nfrom transformers.trainer_utils import EvalPrediction\nfrom sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix\nfrom itertools import product\nfrom pathlib import Path\n\n# Harmless warnings\nwarnings.filterwarnings(\"ignore\", message=\"Some weights of\")\nwarnings.filterwarnings(\"ignore\", message=\"checkpoint\")\nwarnings.filterwarnings(\"ignore\", message=\"AdamW is deprecated\")\n\n# ===== Labels (UPOS) =====\nLABEL_LIST = ['ADJ','ADP','ADV','AUX','CCONJ','DET','INTJ','NOUN','NUM','PART','PRON','PROPN','PUNCT','SCONJ','SYM','VERB','X']\nLABEL2ID = {t:i for i,t in enumerate(LABEL_LIST)}\nID2LABEL = {i:t for t,i in LABEL2ID.items()}\n\n# ===== Config =====\nBASE_CFG = dict(\n    model_name=\"xlm-roberta-base\",\n    max_len=128,\n    train_bs=8,\n    eval_bs=16,\n    # tiny sweep\n    sweep_lrs=[1e-5],     \n    sweep_epochs=[5],    \n    # multi-seed\n    seeds=[42],          \n)\n\ndef _set_all_seeds(seed:int):\n    set_seed(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\n# âœ… FIXED cache path â€” always in /kaggle/working/cache/\ndef _load_ud(file_path:str) -> Dataset:\n    \"\"\"Load and cache UD data safely under /kaggle/working/cache/\"\"\"\n    cache_dir = \"/kaggle/working/cache\"\n    os.makedirs(cache_dir, exist_ok=True)\n    cache = os.path.join(cache_dir, os.path.basename(file_path) + \".cache\")\n\n    if os.path.exists(cache):\n        print(f\"Loading cached dataset: {cache}\")\n        return Dataset.load_from_disk(cache)\n\n    print(f\"Parsing: {file_path}\")\n    rows = []\n    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n        for tokenlist in parse_incr(f):\n            rows.append({\n                \"tokens\": [t[\"form\"] for t in tokenlist],\n                \"upos\": [t[\"upos\"] for t in tokenlist],\n            })\n\n    ds = Dataset.from_pandas(pd.DataFrame(rows))\n    ds.save_to_disk(cache)\n    print(f\"Saved cache: {cache}\")\n    return ds\n\ndef _to_ids(examples):\n    return {\"upos\":[[LABEL2ID.get(tag, LABEL2ID['X']) for tag in tags] for tags in examples[\"upos\"]]}\n\ndef _tokenize_fn(tokenizer, max_len):\n    def f(examples):\n        tok = tokenizer(\n            examples[\"tokens\"],\n            truncation=True, padding=\"max_length\",\n            max_length=max_len, is_split_into_words=True\n        )\n        labels = []\n        for i, lab in enumerate(examples[\"upos\"]):\n            word_ids = tok.word_ids(batch_index=i)\n            prev = None; ids = []\n            for w in word_ids:\n                if w is None:\n                    ids.append(-100)\n                elif w != prev:\n                    ids.append(lab[w])\n                else:\n                    ids.append(-100)\n                prev = w\n            ids += [-100]*(max_len - len(ids))\n            labels.append(ids[:max_len])\n        tok[\"labels\"] = labels\n        return tok\n    return f\n\ndef _flatten_preds_labels(pred_logits, dataset):\n    preds = np.argmax(pred_logits, axis=2)\n    y_true_ids, y_pred_ids = [], []\n    for i in range(len(dataset)):\n        labels = dataset[i][\"labels\"]\n        mask = np.array(labels) != -100\n        y_true_ids.extend(np.array(labels)[mask].tolist())\n        y_pred_ids.extend(np.array(preds[i])[mask].tolist())\n    return y_true_ids, y_pred_ids\n\ndef _metrics_from_ids(y_true_ids, y_pred_ids):\n    y_true = [ID2LABEL[i] for i in y_true_ids]\n    y_pred = [ID2LABEL[i] for i in y_pred_ids]\n    acc = accuracy_score(y_true, y_pred)\n    macro_f1 = f1_score(y_true, y_pred, labels=LABEL_LIST, average=\"macro\", zero_division=0)\n    weighted_f1 = f1_score(y_true, y_pred, labels=LABEL_LIST, average=\"weighted\", zero_division=0)\n    report = classification_report(y_true, y_pred, labels=LABEL_LIST, digits=4, zero_division=0)\n    cm = confusion_matrix(y_true, y_pred, labels=LABEL_LIST)  # counts\n    return acc, macro_f1, weighted_f1, report, cm\n\ndef _plot_confusion(cm_norm, title, out_png):\n    plt.figure(figsize=(12,10))\n    sns.heatmap(cm_norm, annot=False, cmap=\"Blues\", xticklabels=LABEL_LIST, yticklabels=LABEL_LIST)\n    plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.title(title)\n    plt.tight_layout()\n    plt.savefig(out_png)\n    plt.close()\n\n# compute_metrics for Trainer (so eval logs include accuracy each epoch)\ndef _compute_metrics(eval_pred: EvalPrediction):\n    preds = np.argmax(eval_pred.predictions, axis=2)\n    labels = eval_pred.label_ids\n    mask = labels != -100\n    total = mask.sum()\n    correct = ((preds == labels) & mask).sum()\n    acc = float(correct) / float(total) if total > 0 else 0.0\n    return {\"accuracy\": acc}\n\ndef _plot_learning_curve_from_logs(log_history, out_png, title=\"Learning Curve (EN-dev)\"):\n    epochs, eval_loss, eval_acc = [], [], []\n    train_epochs, train_loss = [], []\n    for rec in log_history:\n        if \"eval_loss\" in rec:\n            epochs.append(rec.get(\"epoch\"))\n            eval_loss.append(rec[\"eval_loss\"])\n            eval_acc.append(rec.get(\"eval_accuracy\"))\n        elif \"loss\" in rec and \"epoch\" in rec:\n            train_epochs.append(rec[\"epoch\"])\n            train_loss.append(rec[\"loss\"])\n    plt.figure(figsize=(10,6))\n    if train_epochs:\n        plt.plot(train_epochs, train_loss, label=\"train_loss\", marker=\"o\")\n    if epochs:\n        plt.plot(epochs, eval_loss, label=\"eval_loss\", marker=\"o\")\n    if epochs and any(a is not None for a in eval_acc):\n        ax = plt.gca()\n        ax2 = ax.twinx()\n        ax2.plot(epochs, eval_acc, label=\"eval_accuracy\", marker=\"s\", linestyle=\"--\", color=\"tab:green\")\n        ax2.set_ylabel(\"Eval Accuracy\")\n        ax2.legend(loc=\"lower right\")\n    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(title)\n    plt.legend(loc=\"upper right\")\n    plt.tight_layout()\n    plt.savefig(out_png)\n    plt.close()\n\ndef run_pos_tagging():\n    print(\"\\n\" + \"=\"*50 + \"\\nPOS TAGGING EVALUATION (multi-seed + sweep + learning curves)\\n\" + \"=\"*50)\n    out_root = Path(\"results_msweep\"); out_root.mkdir(exist_ok=True, parents=True)\n\n    # ===== 1) Load & prep data =====\n    print(\"Loading datasetsâ€¦\")\n    en_train = _load_ud(\"data/ud/en_ewt-ud-train.conllu\").map(_to_ids, batched=True)\n    en_dev   = _load_ud(\"data/ud/en_ewt-ud-dev.conllu\").map(_to_ids, batched=True)\n    bn_test  = _load_ud(\"data/ud/bn_bru-ud-test.conllu\").map(_to_ids, batched=True)\n    print(f\"Train {len(en_train)}  Dev {len(en_dev)}  Test {len(bn_test)}\")\n\n    tokenizer = AutoTokenizer.from_pretrained(BASE_CFG[\"model_name\"])\n    tok_fn = _tokenize_fn(tokenizer, BASE_CFG[\"max_len\"])\n\n    print(\"Tokenizingâ€¦\")\n    en_train_tok = en_train.map(tok_fn, batched=True, remove_columns=en_train.column_names)\n    en_dev_tok   = en_dev.map(  tok_fn, batched=True, remove_columns=en_dev.column_names)\n    bn_test_tok  = bn_test.map( tok_fn, batched=True, remove_columns=bn_test.column_names)\n\n    # ===== 2) Zero-shot baseline on BN-test (no selection) =====\n    print(\"\\n--- ZERO-SHOT (bn_test) ---\")\n    zs_model = AutoModelForTokenClassification.from_pretrained(\n        BASE_CFG[\"model_name\"], num_labels=len(LABEL_LIST),\n        id2label=ID2LABEL, label2id=LABEL2ID, ignore_mismatched_sizes=True\n    )\n    zs_trainer = Trainer(\n        model=zs_model,\n        args=TrainingArguments(\n            output_dir=str(out_root/\"zero_shot\"),\n            per_device_eval_batch_size=BASE_CFG[\"eval_bs\"],\n            report_to=\"none\",\n            dataloader_num_workers=2,\n            dataloader_pin_memory=True,\n            fp16=torch.cuda.is_available(),\n        ),\n        data_collator=DataCollatorForTokenClassification(tokenizer)\n    )\n    zs_pred = zs_trainer.predict(bn_test_tok)\n    zs_true_ids, zs_pred_ids = _flatten_preds_labels(zs_pred.predictions, bn_test_tok)\n    zs_acc, zs_mf1, zs_wf1, zs_report, zs_cm = _metrics_from_ids(zs_true_ids, zs_pred_ids)\n    (out_root/\"zero_shot\").mkdir(exist_ok=True, parents=True)\n    with open(out_root/\"zero_shot\"/\"bn_test_report.txt\",\"w\",encoding=\"utf-8\") as f:\n        f.write(f\"acc={zs_acc:.6f}  macroF1={zs_mf1:.6f}  weightedF1={zs_wf1:.6f}\\n\\n{zs_report}\")\n    zs_cm_norm = zs_cm / (zs_cm.sum(axis=1, keepdims=True) + 1e-9)\n    _plot_confusion(zs_cm_norm, \"Zero-shot Confusion (BN test)\", out_root/\"zero_shot\"/\"bn_confusion.png\")\n    del zs_model; torch.cuda.empty_cache()\n\n    # ===== 3) Multi-seed tiny sweep + learning curves =====\n    runs = []\n    aggregate_cm_counts = np.zeros((len(LABEL_LIST), len(LABEL_LIST)), dtype=np.int64)\n\n    for seed in BASE_CFG[\"seeds\"]:\n        print(f\"\\n===== SEED {seed} =====\")\n        _set_all_seeds(seed)\n        best = dict(macro_f1=-1, lr=None, epochs=None, trainer=None, model_dir=None)\n\n        for lr, epochs in product(BASE_CFG[\"sweep_lrs\"], BASE_CFG[\"sweep_epochs\"]):\n            print(f\"  >> Try LR={lr}, Epochs={epochs}\")\n            _set_all_seeds(seed)\n            model = AutoModelForTokenClassification.from_pretrained(\n                BASE_CFG[\"model_name\"], num_labels=len(LABEL_LIST),\n                id2label=ID2LABEL, label2id=LABEL2ID, ignore_mismatched_sizes=True\n            )\n            args = TrainingArguments(\n                output_dir=str(out_root/f\"tmp_s{seed}_lr{lr}_ep{epochs}\"),\n                learning_rate=lr,\n                per_device_train_batch_size=BASE_CFG[\"train_bs\"],\n                per_device_eval_batch_size=BASE_CFG[\"eval_bs\"],\n                num_train_epochs=epochs,\n                eval_strategy=\"epoch\",     \n                save_strategy=\"no\",\n                logging_strategy=\"epoch\",\n                report_to=\"none\",\n                fp16=torch.cuda.is_available(),\n                remove_unused_columns=True,\n                dataloader_num_workers=2,\n                dataloader_pin_memory=True,\n                seed=seed,\n            )\n            trainer = Trainer(\n                model=model, args=args,\n                train_dataset=en_train_tok, eval_dataset=en_dev_tok,\n                data_collator=DataCollatorForTokenClassification(tokenizer),\n                compute_metrics=_compute_metrics\n            )\n            trainer.train()\n\n            # Dev evaluation for selection (macro-F1)\n            dev_pred = trainer.predict(en_dev_tok)\n            y_true_ids, y_pred_ids = _flatten_preds_labels(dev_pred.predictions, en_dev_tok)\n            dev_macro_f1 = f1_score([ID2LABEL[i] for i in y_true_ids],\n                                    [ID2LABEL[i] for i in y_pred_ids],\n                                    labels=LABEL_LIST, average=\"macro\", zero_division=0)\n            print(f\"     dev macro-F1 = {dev_macro_f1:.4f}\")\n\n            if dev_macro_f1 > best[\"macro_f1\"]:\n                best.update(macro_f1=dev_macro_f1, lr=lr, epochs=epochs, trainer=trainer, model_dir=args.output_dir)\n            else:\n                # free GPU\n                del trainer.model; del trainer; torch.cuda.empty_cache()\n\n        # Use best trainer/model for this seed â†’ Final EN-dev & BN-test\n        seed_dir = out_root/f\"seed_{seed}\"; Path(seed_dir).mkdir(exist_ok=True, parents=True)\n        print(f\"Best for seed {seed}: LR={best['lr']}  Epochs={best['epochs']}  (dev macro-F1={best['macro_f1']:.4f})\")\n\n        # Save best model + tokenizer\n        best_dir = Path(seed_dir) / \"best_model\"\n        best[\"trainer\"].save_model(str(best_dir))\n        tokenizer.save_pretrained(str(best_dir))\n        print(f\"Saved best model for seed {seed} to: {best_dir}\")\n\n        # Learning curve from best trainer logs (EN-dev)\n        log_hist = best[\"trainer\"].state.log_history\n        pd.DataFrame(log_hist).to_csv(Path(seed_dir)/\"training_log_history.csv\", index=False)\n        _plot_learning_curve_from_logs(\n            log_hist,\n            Path(seed_dir)/\"learning_curve.png\",\n            title=f\"Learning Curve (EN-dev) â€” seed {seed}, lr={best['lr']}, ep={best['epochs']}\"\n        )\n\n        # EN-dev final report\n        dev_pred = best[\"trainer\"].predict(en_dev_tok)\n        dev_true_ids, dev_pred_ids = _flatten_preds_labels(dev_pred.predictions, en_dev_tok)\n        dev_acc, dev_mf1, dev_wf1, dev_report, dev_cm = _metrics_from_ids(dev_true_ids, dev_pred_ids)\n        with open(Path(seed_dir)/\"en_dev_report.txt\",\"w\",encoding=\"utf-8\") as f:\n            f.write(f\"acc={dev_acc:.6f}  macroF1={dev_mf1:.6f}  weightedF1={dev_wf1:.6f}\\n\\n{dev_report}\")\n        dev_cm_norm = dev_cm / (dev_cm.sum(axis=1, keepdims=True) + 1e-9)\n        _plot_confusion(dev_cm_norm, f\"EN-dev Confusion (seed {seed})\", Path(seed_dir)/\"en_confusion.png\")\n\n        # BN-test final report (held-out)\n        test_pred = best[\"trainer\"].predict(bn_test_tok)\n        test_true_ids, test_pred_ids = _flatten_preds_labels(test_pred.predictions, bn_test_tok)\n        test_acc, test_mf1, test_wf1, test_report, test_cm = _metrics_from_ids(test_true_ids, test_pred_ids)\n        with open(Path(seed_dir)/\"bn_test_report.txt\",\"w\",encoding=\"utf-8\") as f:\n            f.write(f\"acc={test_acc:.6f}  macroF1={test_mf1:.6f}  weightedF1={test_wf1:.6f}\\n\\n{test_report}\")\n        test_cm_norm = test_cm / (test_cm.sum(axis=1, keepdims=True) + 1e-9)\n        _plot_confusion(test_cm_norm, f\"BN-test Confusion (seed {seed})\", Path(seed_dir)/\"bn_confusion.png\")\n\n        # Accumulate results\n        runs.append(dict(seed=seed,\n                         en=dict(acc=dev_acc, macro_f1=dev_mf1, weighted_f1=dev_wf1),\n                         bn=dict(acc=test_acc, macro_f1=test_mf1, weighted_f1=test_wf1)))\n        aggregate_cm_counts += test_cm\n\n        # free GPU\n        del best[\"trainer\"].model; del best[\"trainer\"]; torch.cuda.empty_cache()\n\n    # ===== 4) Aggregate across seeds =====\n    def _agg(metric):\n        en_vals = [r[\"en\"][metric] for r in runs]\n        bn_vals = [r[\"bn\"][metric] for r in runs]\n        return (np.mean(en_vals), np.std(en_vals), np.mean(bn_vals), np.std(bn_vals))\n\n    mean_en_acc, std_en_acc, mean_bn_acc, std_bn_acc = _agg(\"acc\")\n    mean_en_mf1, std_en_mf1, mean_bn_mf1, std_bn_mf1 = _agg(\"macro_f1\")\n    mean_en_wf1, std_en_wf1, mean_bn_wf1, std_bn_wf1 = _agg(\"weighted_f1\")\n\n    agg_cm_norm = aggregate_cm_counts / (aggregate_cm_counts.sum(axis=1, keepdims=True) + 1e-9)\n    _plot_confusion(agg_cm_norm, \"BN-test Confusion (Aggregate over seeds)\", out_root/\"bn_confusion_aggregate.png\")\n\n    summary = f\"\"\"FINAL SUMMARY over {len(runs)} seed(s)\nEN-dev : acc={mean_en_acc:.4f}Â±{std_en_acc:.4f} | macroF1={mean_en_mf1:.4f}Â±{std_en_mf1:.4f} | weightedF1={mean_en_wf1:.4f}Â±{std_en_wf1:.4f}\nBN-test: acc={mean_bn_acc:.4f}Â±{std_bn_acc:.4f} | macroF1={mean_bn_mf1:.4f}Â±{std_bn_mf1:.4f} | weightedF1={mean_bn_wf1:.4f}Â±{std_bn_wf1:.4f}\n\nZero-shot BN-test (single run): acc={zs_acc:.4f} | macroF1={zs_mf1:.4f} | weightedF1={zs_wf1:.4f}\n\"\"\"\n    print(\"\\n\" + summary)\n    out_root.joinpath(\"summary.txt\").write_text(summary, encoding=\"utf-8\")\n\n    return {\n        \"zero_shot_bn\": dict(acc=zs_acc, macro_f1=zs_mf1, weighted_f1=zs_wf1),\n        \"runs\": runs,\n        \"mean_std\": {\n            \"en_dev\": {\n                \"acc\": (mean_en_acc, std_en_acc),\n                \"macro_f1\": (mean_en_mf1, std_en_mf1),\n                \"weighted_f1\": (mean_en_wf1, std_en_wf1),\n            },\n            \"bn_test\": {\n                \"acc\": (mean_bn_acc, std_bn_acc),\n                \"macro_f1\": (mean_bn_mf1, std_bn_mf1),\n                \"weighted_f1\": (mean_bn_wf1, std_bn_wf1),\n            },\n        }\n    }\n\nif __name__ == \"__main__\":\n    run_pos_tagging()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T22:25:19.676661Z","iopub.execute_input":"2025-10-29T22:25:19.677577Z","iopub.status.idle":"2025-10-29T22:25:19.690293Z","shell.execute_reply.started":"2025-10-29T22:25:19.677541Z","shell.execute_reply":"2025-10-29T22:25:19.689321Z"}},"outputs":[{"name":"stdout","text":"Writing postaging.py\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from postaging import run_pos_tagging\nresults = run_pos_tagging()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T22:25:27.299451Z","iopub.execute_input":"2025-10-29T22:25:27.299950Z","iopub.status.idle":"2025-10-29T23:00:28.048979Z","shell.execute_reply.started":"2025-10-29T22:25:27.299907Z","shell.execute_reply":"2025-10-29T23:00:28.048072Z"}},"outputs":[{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1761776736.019000      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1761776736.078407      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"\n==================================================\nPOS TAGGING EVALUATION (multi-seed + sweep + learning curves)\n==================================================\nLoading datasetsâ€¦\nParsing: data/ud/en_ewt-ud-train.conllu\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/12544 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73997bc2c41e47aebccb290328707c89"}},"metadata":{}},{"name":"stdout","text":"Saved cache: /kaggle/working/cache/en_ewt-ud-train.conllu.cache\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/12544 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aacf78404a2e4fbeb71ca59e5c73f338"}},"metadata":{}},{"name":"stdout","text":"Parsing: data/ud/en_ewt-ud-dev.conllu\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/2001 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b7a6006094c4f4da0938667a0c1c3ae"}},"metadata":{}},{"name":"stdout","text":"Saved cache: /kaggle/working/cache/en_ewt-ud-dev.conllu.cache\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2001 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6dae6a31aa24e3ea488029152544d92"}},"metadata":{}},{"name":"stdout","text":"Parsing: data/ud/bn_bru-ud-test.conllu\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/56 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01305e0baa084b38a2e057093a749db0"}},"metadata":{}},{"name":"stdout","text":"Saved cache: /kaggle/working/cache/bn_bru-ud-test.conllu.cache\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/56 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"161f22d7a4f64f13a4b867e3d0e9cfec"}},"metadata":{}},{"name":"stdout","text":"Train 12544  Dev 2001  Test 56\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de031755e8aa4f2cb1a27153d2d66e82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d36298d932fe470182c92dcdc8d68f44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0350509ff5014b15978628cefdd7e820"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c62929b5c6b2493aaec2ab13aabfaf1a"}},"metadata":{}},{"name":"stdout","text":"Tokenizingâ€¦\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/12544 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03efaab6513340d0a40c1e3da1d00da2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2001 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"468776baf5cd46aaa03ac6a1c927f843"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/56 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41a4c740333444cf9fb0141d85cc28ce"}},"metadata":{}},{"name":"stdout","text":"\n--- ZERO-SHOT (bn_test) ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c47337eeeb2a422fbd0b58ab83516807"}},"metadata":{}},{"name":"stderr","text":"Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n===== SEED 42 =====\n  >> Try LR=1e-05, Epochs=5\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3920' max='3920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3920/3920 33:39, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.397900</td>\n      <td>0.121926</td>\n      <td>0.967934</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.090100</td>\n      <td>0.100012</td>\n      <td>0.974089</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.064100</td>\n      <td>0.094831</td>\n      <td>0.976441</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.049700</td>\n      <td>0.096202</td>\n      <td>0.976715</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.042500</td>\n      <td>0.095853</td>\n      <td>0.977107</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"     dev macro-F1 = 0.9670\nBest for seed 42: LR=1e-05  Epochs=5  (dev macro-F1=0.9670)\nSaved best model for seed 42 to: results_msweep/seed_42/best_model\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"\nFINAL SUMMARY over 1 seed(s)\nEN-dev : acc=0.9771Â±0.0000 | macroF1=0.9670Â±0.0000 | weightedF1=0.9770Â±0.0000\nBN-test: acc=0.8688Â±0.0000 | macroF1=0.6046Â±0.0000 | weightedF1=0.8701Â±0.0000\n\nZero-shot BN-test (single run): acc=0.1469 | macroF1=0.0203 | weightedF1=0.0721\n\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\nimport torch\n\nMODEL_DIR = \"/kaggle/working/results_msweep/seed_42/best_model\"  # pick your seedâ€™s folder\n\ntok = AutoTokenizer.from_pretrained(MODEL_DIR)\nmodel = AutoModelForTokenClassification.from_pretrained(MODEL_DIR)\ndevice = 0 if torch.cuda.is_available() else -1\n\ntagger = pipeline(\"token-classification\", model=model, tokenizer=tok, device=device, aggregation_strategy=\"simple\")\n\nfor s in [\"à¦†à¦®à¦¿ à¦†à¦œ à¦¬à¦¾à¦œà¦¾à¦°à§‡ à¦¯à¦¾à¦šà§à¦›à¦¿à¥¤\", \"à¦¬à¦¾à¦‚à¦²à¦¾ à¦­à¦¾à¦·à¦¾ à¦–à§à¦¬ à¦¸à§à¦¨à§à¦¦à¦°à¥¤\"]:\n    print(\"\\nTEXT:\", s)\n    for item in tagger(s):\n        print(f\"{item['word']:>15s} -> {item['entity_group']}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T23:02:21.463728Z","iopub.execute_input":"2025-10-29T23:02:21.464102Z","iopub.status.idle":"2025-10-29T23:02:22.759983Z","shell.execute_reply.started":"2025-10-29T23:02:21.464070Z","shell.execute_reply":"2025-10-29T23:02:22.758955Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"\nTEXT: à¦†à¦®à¦¿ à¦†à¦œ à¦¬à¦¾à¦œà¦¾à¦°à§‡ à¦¯à¦¾à¦šà§à¦›à¦¿à¥¤\n            à¦†à¦®à¦¿ -> PRON\n             à¦†à¦œ -> ADV\n          à¦¬à¦¾à¦œà¦¾à¦° -> NOUN\n              à§‡ -> ADP\n         à¦¯à¦¾à¦šà§à¦›à¦¿ -> VERB\n              à¥¤ -> PUNCT\n\nTEXT: à¦¬à¦¾à¦‚à¦²à¦¾ à¦­à¦¾à¦·à¦¾ à¦–à§à¦¬ à¦¸à§à¦¨à§à¦¦à¦°à¥¤\n          à¦¬à¦¾à¦‚à¦²à¦¾ -> ADJ\n           à¦­à¦¾à¦·à¦¾ -> NOUN\n            à¦–à§à¦¬ -> ADV\n         à¦¸à§à¦¨à§à¦¦à¦° -> ADJ\n              à¥¤ -> PUNCT\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}